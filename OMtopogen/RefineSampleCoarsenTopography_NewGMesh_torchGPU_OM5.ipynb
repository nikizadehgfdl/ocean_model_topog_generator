{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FzPFwAc4aE5Q"
   },
   "source": [
    "## This notebook utilizes the tool to make a refine-sample-coarsen model topography "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GMesh_torch\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "import torch\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jPKG4PO7mJ5T"
   },
   "source": [
    "## GridMesh Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hu7z0eIpTfTZ"
   },
   "source": [
    "## Read GEBCO dataset for topography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read topo data\n",
    "#! cp -n /archive/gold/datasets/topography/GEBCO_2023/GEBCO_2023.nc .\n",
    "#! ln -s /home/Niki.Zadeh/datasets .datasets\n",
    "#source_datafile='.datasets/GEBCO_2020.nc'\n",
    "source_datafile='.datasets/GEBCO_2023.nc'\n",
    "with netCDF4.Dataset(source_datafile) as nc:\n",
    "    topo_lons = nc.variables['lon'][:].filled(0.)\n",
    "    topo_lats = nc.variables['lat'][:].filled(0.)\n",
    "    topo_elvs = nc.variables['elevation'][:,:].filled(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_topo_lons=torch.from_numpy(topo_lons).to(device)\n",
    "t_topo_lats=torch.from_numpy(topo_lats).to(device)\n",
    "t_topo_elvs=torch.from_numpy(topo_elvs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_topo_elvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_topo_global = GMesh_torch.UniformEDS( t_topo_lons, t_topo_lats, t_topo_elvs, device)\n",
    "src_topo_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' topography grid array shapes: ' , topo_lons.shape,topo_lats.shape,topo_elvs.shape)\n",
    "print(' topography longitude range:',topo_lons.min(),topo_lons.max())\n",
    "print(' topography latitude range:',topo_lats.min(),topo_lats.max())\n",
    "#print(' Is mesh uniform?', GMesh.is_mesh_uniform( topo_lons, topo_lats ) )\n",
    "#GEBCO_2014_2D.nc\n",
    "# topography grid array shapes:  (43200,) (21600,) (21600, 43200)\n",
    "# topography longitude range: -299.995833333 59.9958333333\n",
    "# topography latitude range: -89.9958333333 89.9958333333\n",
    "# Is mesh uniform? True\n",
    "#GEBCO_2020.nc\n",
    "# topography grid array shapes:  (86400,) (43200,) (43200, 86400)\n",
    "# topography longitude range: -299.9979166666667 59.99791666666667\n",
    "# topography latitude range: -89.99791666666667 89.99791666666667\n",
    "# Is mesh uniform? True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xDhpqHHKcmj8"
   },
   "source": [
    "## Read the target grid\n",
    "\n",
    "Terget grid is the underlying finite element 2D supergrid to be used in the Ocean model. Here we choose a 1/4 degree Mercator grid  generated by using the [grid_generation tool](https://github.com/nikizadehgfdl/grid_generation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read target mesh\n",
    "#OM5 grid\n",
    "#scp /archive/jpk/datasets/OM5/OM5_025/v20240311/ocean_hgrid.nc Niki.Zadeh@lscamd50-d:/home/Niki.Zadeh/datasets/ocean_hgrid_OM5p25v20240311.nc\n",
    "#! ln -s /home/Niki.Zadeh/datasets .datasets\n",
    "#ocean_hgrid_file='.datasets/ocean_hgrid.Merc.4deg.nc'\n",
    "#NtileI, NtileJ, max_refinement = 30, 1, 9\n",
    "ocean_hgrid_file='.datasets/OM5p25v20240311_jpk/ocean_hgrid_OM5p25v20240311.nc'\n",
    "with netCDF4.Dataset(ocean_hgrid_file) as nc:\n",
    "    lon=nc.variables['x'][::2,::2]\n",
    "    lat=nc.variables['y'][::2,::2]\n",
    "t_lon=torch.from_numpy(lon).to(device)\n",
    "t_lat=torch.from_numpy(lat).to(device)\n",
    "targG = GMesh_torch.GMesh_torch( lon=t_lon, lat=t_lat )\n",
    "targG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMesh_torch.pfactor( targG.ni ), GMesh_torch.pfactor( targG.nj )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targG.lon.shape[0],targG.lon[0,0],t_lon[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import create_topog_refinedSampling as topotool\n",
    "#jllc,illc,status1=topotool.get_indices1D(topo_lons, topo_lats ,targG.lon[0,0] ,targG.lat[0,0])\n",
    "#jurc,iurc,status2=topotool.get_indices1D(topo_lons, topo_lats ,targG.lon[0,-1],targG.lat[-1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convol( levels, h, f, verbose=False ):\n",
    "    \"\"\"Coarsens the product of h*f across all levels\"\"\"\n",
    "    levels[-1].height = ( h * f ).reshape(levels[-1].nj,levels[-1].ni)\n",
    "    for k in range( len(levels) - 1, 0, -1 ):\n",
    "        if verbose: print('Coarsening {} -> {}'.format(k,k-1))\n",
    "        levels[k].coarsenby2( levels[k-1] )\n",
    "    return levels[0].height  \n",
    "\n",
    "def rough( levels, h, h2min=1.e-7 ):\n",
    "    \"\"\"Calculates both mean of H, and variance of H relative to a plane\"\"\"\n",
    "    # Construct weights for moment calculations\n",
    "    nx = 2**( len(levels) - 1 )\n",
    "    x = ( np.arange(nx) - ( nx - 1 ) /2 ) * np.sqrt( 12 / ( nx**2 - 1 ) ) # This formula satisfies <x>=0 and <x^2>=1\n",
    "    X, Y = np.meshgrid( x, x )\n",
    "    X, Y = X.reshape(1,nx,1,nx), Y.reshape(1,nx,1,nx)\n",
    "    h = h.reshape(levels[0].nj,nx,levels[0].ni,nx)\n",
    "    # Now calculate moments\n",
    "    H2 = convol( levels, h, h ) # mean of h^2\n",
    "    HX = convol( levels, h, X ) # mean of h * x\n",
    "    HY = convol( levels, h, Y ) # mean of h * y\n",
    "    H = convol( levels, h, np.ones((1,nx,1,nx)) ) # mean of h = mean of h * 1\n",
    "    # The variance of deviations from the plane = <h^2> - <h>^2 - <h*x>^2 - <h*y>^2 given <x>=<y>=0 and <x^2>=<y^2>=1\n",
    "    return H, H2 - H**2 - HX**2 - HY**2 + h2min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def do_RSC_new(targG,src_topo_global,NtileI=1, NtileJ=1, max_refinement=10):\n",
    "    \"\"\"Apply the RSC algoritm using a fixed number of refinements max_refinement\"\"\"\n",
    "    di, dj = targG.ni // NtileI, targG.nj // NtileJ\n",
    "    assert di*NtileI == targG.ni\n",
    "    assert dj*NtileJ == targG.nj\n",
    "    print('window size dj,di =',dj,di,'full model nj,ni=',targG.nj, targG.ni)\n",
    "    Hcnt = np.zeros((targG.nj, targG.ni)) # Diagnostic: counting which cells we are working on\n",
    "    Htarg, H2targ = np.zeros((targG.nj, targG.ni)), np.zeros((targG.nj, targG.ni))\n",
    "    for j in range(NtileJ ):\n",
    "        csj, sj = slice( j*dj, (j+1)*dj ), slice( j*dj, (j+1)*dj+1 )\n",
    "        for i in range(NtileI ):\n",
    "            csi, si = slice( i*di, (i+1)*di ), slice( i*di, (i+1)*di+1 ) # Slices of target grid\n",
    "            Hcnt[csj,csi] = Hcnt[csj,csi] + 1 # Diagnostic: counting which cells we are working on\n",
    "            G = GMesh_torch.GMesh_torch( lon=targG.lon[sj,si], lat=targG.lat[sj,si],device=device )\n",
    "            print('J,I={},{} {:.1f}%, {}\\n   window lon={}:{}, lat={}:{}\\n   jslice={}, islice={}'.format( \\\n",
    "                j, i, 100*(j*NtileI+i)/(NtileI*NtileJ), G, G.lon.min(), G.lon.max(), G.lat.min(), G.lat.max(), sj, si ))\n",
    "            levels = G.refine_loop( src_topo_global, resolution_limit=False, fixed_refine_level=max_refinement, timers=False, verbose=False)\n",
    "            ## Use nearest neighbor topography to populate the finest grid\n",
    "            levels[-1].project_source_data_onto_target_mesh( src_topo_global )\n",
    "            ## Now recursively coarsen\n",
    "            h, h2 = rough( levels, levels[-1].height )\n",
    "            # Store window in final array\n",
    "            Htarg[csj,csi] = h\n",
    "            H2targ[csj,csi] = h2\n",
    "    print( Hcnt.min(), Hcnt.max(), '<-- should both be 1 for full model' )\n",
    "    return  Htarg, H2targ\n",
    "    \n",
    "st = time.time()\n",
    "#Test grid\n",
    "#NtileI, NtileJ, max_refinement = 30, 1, 9\n",
    "#OM5p25v20240311\n",
    "#NtileI, NtileJ, max_refinement = 3*2, 43*3*3, 7\n",
    "NtileI, NtileJ, max_refinement = 3*2*2*2, 43*3*3, 8\n",
    "Htarg, H2targ = do_RSC_new(targG,src_topo_global,NtileI, NtileJ, max_refinement)    \n",
    "et = time.time() - st\n",
    "print('Execution time:', et, 'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OM5p25v20240311 topography\n",
    "#torch CPU, rf=7 Execution time:  1557.25546169281 seconds\n",
    "#\n",
    "#numpy CPU, rf=8 Execution time: 60652.4 seconds ~ 17.8 hrs\n",
    "#torch CPU, rf=8 Execution time:  5834.2 seconds ~  1.6 hrs\n",
    "#torch GPU, rf=8 Execution time:  3093.6 seconds ~  0.9 hrs\n",
    "#\n",
    "#Test grid ocean_hgrid.Merc.4deg.nc and GEBCO2020\n",
    "#After every refinement the number of hits increases by almost a factor of 4. \n",
    "#So when more than 25% is hit, upon a refinement the resolution of refined grid \n",
    "# becomes more than the resolution of the source and each source point\n",
    "# gets hit multiple times and the algorithm should be considered as converged.\n",
    "#\n",
    "#NtileI=NtileJ=1\n",
    "#numpy cpu\n",
    "#rf=8  Hit  253624320  out of  2688360168  cells,    9.4341644776221  percent, time: 141.05 seconds\n",
    "#rf=9  Hit 1014497280  out of  2688508800  cells,   37.7345716703624  percent, time: 570.34 seconds \n",
    "#torch cpu\n",
    "#rf=6  Hit   15851520  out of  2687952352  cells,    0.5897247392873  percent, time:   1.45 seconds\n",
    "#rf=8  Hit  253624320  out of  2688297936  cells,    9.4343828711699  percent, time:   8.28 seconds\n",
    "#rf=9  Hit 1014497280  out of  2688384332  cells,   37.7363187221550  percent, time:  20.34 seconds\n",
    "#rf=10 Hit 4057989120  out of  3175139396  cells,  127.8050697588963  percent, time: 153.27 seconds\n",
    "#torch gpu\n",
    "#rf=8  Hit  253624320  out of  -1606669360  cells,  -15.785719595723167  percent time: 5.298048973083496 seconds\n",
    "#rf=9 OutOfMemoryError: CUDA out of memory. Tried to allocate 3.78 GiB (GPU 0; 31.73 GiB total capacity; 28.37 GiB already allocated; 2.97 GiB free; 28.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
    "#NtileI=10, NtileJ=1\n",
    "#rf=9  Hit  101449728  out of  268850880  cells,  37.7345716703624  percent,  time: 20.95916986465454 seconds  \n",
    "#rf=10 OutOfMemoryError: CUDA out of memory. Tried to allocate 1.51 GiB (GPU 0; 31.73 GiB total capacity; 27.49 GiB already allocated; 1.46 GiB free; 29.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
    "#NtileI=30, NtileJ=1\n",
    "#gpu: rf=10 Hit  135266304  out of  89619840  cells,  150.93343616770574  percent, time:  87.05817294120789 seconds\n",
    "#cpu: rf=10 Hit  135266304  out of  89619840  cells,  150.93343616770574  percent, time: 120.57575964927673 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with netCDF4.Dataset('new_topo_OM5_grid_r{}_{}x{}.nc'.format(max_refinement, NtileI, NtileJ),'w','clobber') as nc:\n",
    "    nx = nc.createDimension('nx', Htarg.shape[1])\n",
    "    ny = nc.createDimension('ny', Htarg.shape[0])\n",
    "    ntiles = nc.createDimension('ntiles', 1)\n",
    "    z = nc.createVariable('depth', float, ('ny','nx') )\n",
    "    z.units='meters'\n",
    "    z2 = nc.createVariable('h2', float, ('ny','nx'))\n",
    "    z2.units='meters^2'\n",
    "    z[:,:] = -Htarg[:,:]\n",
    "    z2[:,:] = H2targ[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls new_topo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with netCDF4.Dataset('new_topo_OM5_grid_r{}_{}x{}.nc'.format(max_refinement, NtileI, NtileJ)) as nc:\n",
    "    depth = nc.variables['depth'][:,:]\n",
    "    roughness = nc.variables['h2'][:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare with the raw results of OM5p25v20240311\n",
    "with netCDF4.Dataset('.datasets/OM5p25v20240311_jpk/new_topo_OM5_grid_r8_24x387.nc') as nc:\n",
    "    depth_OM5 = nc.variables['depth'][:,:]\n",
    "    rough_OM5 = nc.variables['h2'][:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#depth_diff=depth-depth_OM5\n",
    "#plt.figure(figsize=(14,8)); \n",
    "#plt.subplot(121); plt.pcolormesh( depth); plt.colorbar();\n",
    "#plt.subplot(122); plt.pcolormesh( depth_diff); plt.colorbar();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rough_diff=roughness-rough_OM5\n",
    "#plt.figure(figsize=(14,8)); \n",
    "#plt.subplot(121); plt.pcolormesh(roughness); plt.colorbar();\n",
    "#plt.subplot(122); plt.pcolormesh(rough_diff); plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Copy of algorithm_dev.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
